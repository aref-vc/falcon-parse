# Falcon Parse Environment Configuration

# Gemini AI API Key (required)
GEMINI_API_KEY=your_gemini_api_key_here

# Server Configuration
BACKEND_PORT=8010
FRONTEND_PORT=3010
BACKEND_HOST=0.0.0.0

# Application Settings
MAX_CONCURRENT_SCRAPES=5
SCRAPE_TIMEOUT=30
TEMP_FILE_CLEANUP_HOURS=24

# Enhanced Scraping Limits (NEW - prevents infinite loops)
# These are the DEFAULT limits - problematic sites use stricter values automatically

# Maximum scroll attempts during dynamic content loading
MAX_SCROLL_ATTEMPTS=20

# Maximum pagination page clicks  
MAX_PAGINATION_PAGES=5

# Maximum time (seconds) spent on dynamic content loading
MAX_DYNAMIC_TIME=60

# Maximum page height in pixels before stopping
MAX_PAGE_HEIGHT=500000

# Maximum content items before stopping
MAX_CONTENT_ITEMS=50000

# Advanced Safeguards (NEW)
# Threshold for considering content changes "significant"
SIGNIFICANT_HEIGHT_CHANGE=5000  # pixels
SIGNIFICANT_ITEMS_CHANGE=1000   # items

# Stop scraping if single iteration adds more than this many items
EXCESSIVE_GROWTH_THRESHOLD=5000

# Maximum consecutive large changes before stopping
MAX_CONSECUTIVE_CHANGES=5

# Development Settings
LOG_LEVEL=INFO
DEBUG_MODE=false

# Site-Specific Overrides
# The system automatically applies stricter limits for known problematic sites:
# - vcsheet.com: 3 scrolls, 5000 items, 30 seconds
# - crunchbase.com: 5 scrolls, 10000 items, 45 seconds  
# - linkedin.com: 4 scrolls, 3000 items, 40 seconds
# - indeed.com: 6 scrolls, 8000 items, 50 seconds
# - glassdoor.com: 4 scrolls, 4000 items, 35 seconds